{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of A_1 for AG use.ipynb","provenance":[{"file_id":"1g91OoMZay_t9UHENzsr3WWaPLM1okVm-","timestamp":1598901308155}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"1CyebN0ddBEB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":121},"executionInfo":{"status":"ok","timestamp":1599060250807,"user_tz":-180,"elapsed":43017,"user":{"displayName":"Alexandra G","photoUrl":"","userId":"12867522197621895843"}},"outputId":"9ad36475-9413-4479-9698-19d5837a7c97"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"t0alSmKadCM0","colab_type":"code","colab":{}},"source":["import pandas as pd\n","import os\n","\n","os.chdir('..')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QoIZv-FVhoAM","colab_type":"code","colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":73},"executionInfo":{"status":"ok","timestamp":1599060268373,"user_tz":-180,"elapsed":17646,"user":{"displayName":"Alexandra G","photoUrl":"","userId":"12867522197621895843"}},"outputId":"19ef0adf-91e3-439a-f54b-483616af941c"},"source":["from google.colab import files\n","uploaded = files.upload()\n","#questions = pd.read_csv('./MLResearchProject/Data_Sets/Questions_300.csv')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-80c31aae-1299-4c5e-acc5-a5706f9e4a2e\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-80c31aae-1299-4c5e-acc5-a5706f9e4a2e\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving untaggedA.csv to untaggedA.csv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RXLumxS_dl_R","colab_type":"code","colab":{}},"source":["import io\n","questions_og = pd.read_csv(io.BytesIO(uploaded['untaggedA.csv']))\n","\n","questions = questions_og"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B9zKLR92enJY","colab_type":"text"},"source":["The following 3 blocks carry out the Pre-processing of the dataset"]},{"cell_type":"code","metadata":{"id":"jmHXWRk0d5mB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1599060269332,"user_tz":-180,"elapsed":8354,"user":{"displayName":"Alexandra G","photoUrl":"","userId":"12867522197621895843"}},"outputId":"f7a3e905-d5d5-468b-8ccd-e91599fbde9f"},"source":["questions['Question_Processed'] = questions['Question'].map(lambda x: x.lower())\n","data_og = questions.Question_Processed.values.tolist()\n","\n","import re\n","\n","#Applying this tokenisation approach to the entire input dataset\n","test_text = []\n","for sentence in data_og:\n","  token_punct = re.split('\\s',sentence)\n","  test_text.append(token_punct)\n","\n","#Defining function words to search for\n","words_funct = ['for', 'if', 'while', 'print', 'boolean', 'bigo', 'else', 'elseif' ]\n","\n","#Removing function words when used outside of the appropriate context\n","text_processed = [[word for word in doc if word not in words_funct] for doc in test_text]\n","\n","from nltk.tokenize.treebank import TreebankWordDetokenizer\n","\n","#Reversing the process of tokenisation\n","questions_testproc = []\n","for sentence in text_processed:\n","  detoken = TreebankWordDetokenizer().detokenize(sentence)\n","  questions_testproc.append(detoken)\n","\n","from pandas import DataFrame\n","questions_proc = DataFrame(questions_testproc,columns=['Questions_Processed'])\n","\n","questions_proc['Question_Processed'] = questions_proc['Questions_Processed'].map(lambda x: re.sub('[,\\.!?]', '', x))\n","questions_proc.index = questions.index\n","questions['Question_Processed'] = questions_proc['Question_Processed']\n","\n","#Tokenising sentences into individual words with no punctuation\n","#Note: This process tends to remove any mathematical arguments from the questions \n","import gensim\n","from gensim.utils import simple_preprocess\n","\n","def sent_to_words(sentences):\n","    for sentence in sentences:\n","        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n","        #deacc=True removes accent marks\n","\n","data = questions.Question_Processed.values.tolist()\n","data_words = list(sent_to_words(data))\n","\n","#Forming Bigrams and Trigrams\n","bigram = gensim.models.Phrases(data_words, min_count = 5, threshold = 100)\n","trigram = gensim.models.Phrases(bigram[data_words], threshold = 100)\n","\n","bigram_mod = gensim.models.phrases.Phraser(bigram)\n","trigram_mod = gensim.models.phrases.Phraser(trigram)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n","  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"ejPq307pgnZH","colab_type":"text"},"source":["Defining functions for processing"]},{"cell_type":"code","metadata":{"id":"X5j8697rhoAv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":50},"executionInfo":{"status":"ok","timestamp":1599060269809,"user_tz":-180,"elapsed":7397,"user":{"displayName":"Alexandra G","photoUrl":"","userId":"12867522197621895843"}},"outputId":"edc15058-9ebe-443b-c29e-02b9089d34fd"},"source":["import nltk\n","nltk.download('stopwords')\n","from nltk.corpus import stopwords\n","\n","stop_words = stopwords.words('english')\n","stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n","\n","words_keep = ['for', 'if', 'while', 'print', 'Boolean', 'BigO', 'else', 'elseif' ]\n","new_stop_words = set(stop_words).difference(words_keep)\n","newer_stop_words = [word for word in stop_words if word not in words_keep] \n","\n","#Define functions for stopwords, bigrams, trigrams and lemmatization\n","\n","def remove_stopwords(texts):\n","    return [[word for word in simple_preprocess(str(doc)) if word not in new_stop_words] for doc in texts]\n","\n","def make_bigrams(texts):\n","    return [bigram_mod[doc] for doc in texts]\n","\n","def make_trigrams(texts):\n","    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n","\n","def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV','SCONJ','ADP','PROPN','X']):\n","  \"\"\"https://spacy.io/api/annotation\"\"\"\n","  texts_out = []\n","  texts_post = []\n","  for sent in texts:\n","      doc = nlp(\" \".join(sent))\n","      texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n","      #texts_post.append([token.pos for token in doc])\n","      #print(texts_out)\n","  return texts_out"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"JZ28OcfBgxhP","colab_type":"text"},"source":["Stopword Removal and Lemmatization"]},{"cell_type":"code","metadata":{"id":"a6K1vAO2e4sV","colab_type":"code","colab":{}},"source":["import spacy\n","# Remove Stop Words\n","data_words_nostops = remove_stopwords(data_words)\n","\n","# Form Bigrams\n","data_words_bigrams = make_bigrams(data_words_nostops)\n","\n","# Form Trigrams\n","#data_words_trigrams = make_trigrams(data_words_nostops)\n","\n","# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n","nlp = spacy.load(\"en_core_web_sm\", disable = ['parser', 'ner'])\n","\n","# Do lemmatization keeping only noun, adj, vb, adv\n","data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV','SCONJ','ADP','PROPN','X'])\n","\n","import gensim.corpora as corpora\n","\n","# Create Dictionary\n","id2word = corpora.Dictionary(data_lemmatized)\n","# Create Corpus\n","texts = data_lemmatized\n","# Term Document Frequency\n","corpus = [id2word.doc2bow(text) for text in texts]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8aegb97HgcVD","colab_type":"code","colab":{}},"source":["from gensim.models import HdpModel"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cipCfqpEg44Q","colab_type":"text"},"source":["Defining functions to produce results"]},{"cell_type":"code","metadata":{"id":"iZQZiQGOg9pG","colab_type":"code","colab":{}},"source":["def hdp_vals(n,corpus_set,id2word_set):\n","  hdp_model = HdpModel(corpus=corpus_set,id2word=id2word_set,T=n)\n","  alpha_vec = hdp_model.hdp_to_lda()[0]\n","\n","  x = len(alpha_vec[alpha_vec>1/n])\n","  y = len(alpha_vec[alpha_vec>1/x])\n","  z = len(alpha_vec[alpha_vec>1/y])\n","\n","  return(x,y,z)\n","\n","def formatted_table(lda_model,corpus,data_lemmatized):\n","  df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data_lemmatized)\n","\n","  # Format\n","  df_dominant_topic = df_topic_sents_keywords.reset_index()\n","  df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n","  df_dominant_topic['Question'] = questions['Question']\n","\n","  df_dominant_topic.sort_values(\"Dominant_Topic\", axis = 0, ascending = True, \n","                  inplace = True, na_position ='last')\n","  return(df_dominant_topic)\n","\n","def get_used_topics(n,corpus,data_lemmatized,id2word):\n","  lda_model = gensim.models.LdaMulticore(corpus=corpus, id2word=id2word, num_topics=n, random_state=100, chunksize=100, passes=10, alpha=0.31, eta=0.41)\n","  table = formatted_table(lda_model,corpus,data_lemmatized)\n","  \n","  index_list = list(table.index)\n","  topics_used = []\n","    \n","  for i in index_list:\n","    topics_used.append(table.at[i,'Dominant_Topic'])\n","\n","  x = len(set(topics_used))\n","\n","  return(x)\n","\n","def format_topics_sentences(ldamodel=None, corpus=corpus, texts=data):\n","    # Init output\n","    sent_topics_df = pd.DataFrame()\n","\n","    # Get main topic in each document\n","    for i, row_list in enumerate(ldamodel[corpus]):\n","        row = row_list[0] if ldamodel.per_word_topics else row_list            \n","        # print(row)\n","        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n","        # Get the Dominant topic, Perc Contribution and Keywords for each document\n","        for j, (topic_num, prop_topic) in enumerate(row):\n","            if j == 0:  # => dominant topic\n","                wp = ldamodel.show_topic(topic_num)\n","                topic_keywords = \", \".join([word for word, prop in wp])\n","                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n","            else:\n","                break\n","    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n","\n","    # Add original text to the end of the output\n","    contents = pd.Series(texts)\n","    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n","    return(sent_topics_df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Q-6sUAMQlWw9","colab_type":"code","colab":{}},"source":["import tqdm\n","import time\n","import shutil"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9oQDkEFa1r2Z","colab_type":"code","colab":{}},"source":["def get_averages(vector,runs=100):\n","\n","  #Establishing vectors to hold average results\n","  topic_final_vec = []\n","  average_topics = []\n","\n","  #Establish vectors to hold the Run details for each Question set as DataFrame objects\n","  run_dat = []\n","  length_dat = []\n","\n","  #Progess Bar\n","  pbar = tqdm.tqdm(total=len(vector))\n","\n","  for i in vector:\n","    #Start timer\n","    start = time.process_time()\n","\n","    #Establish vector to hold the details of each run as Dataframe objects\n","    outputs = []\n","\n","    #Establishing the appropriate sets to use for each step\n","    data_lemmatized_set = data_lemmatized[:i]\n","    corpus_set = corpus[:i]\n","    id2word_set = corpora.Dictionary(data_lemmatized_set)\n","\n","    #Establishing vectors to hold the runs results\n","    topic_vec = []\n","    ratio_vec = []\n","    length_vec = []\n","\n","    for k in list(range(0,runs,1)):\n","      #Compute the value of HDP(2)\n","      x = hdp_vals(i,corpus_set,id2word_set)[1]\n","\n","      #Establish vector to hold topic numbers for the run\n","      y = []\n","      y.append(x)\n","\n","      #Establish vector to hold ratios for the run\n","      z = []\n","\n","      #Initialise ratio, topic number and length to start the run\n","      ratio = 0\n","      x1 = x\n","      n = 0\n","\n","      #Iteration Process\n","      while ratio<1 and n<3 :\n","        #Determine the number of topics used and the new ratio\n","        t = get_used_topics(x1,corpus_set,data_lemmatized_set,id2word_set)\n","        ratio = t/x1\n","        \n","        #Update the topic number and length; Record the ratio\n","        x1 = t\n","        z.append(ratio)\n","        n += 1\n","\n","        #Check to end the loop\n","        if ratio == 1 or n == 3 :\n","          break\n","\n","        #Record the new number of topics (if there is one)\n","        y.append(t)\n","\n","      #Recording values to the appropriate vector for average details\n","      topic_final_vec.append(y[-1])\n","\n","      #Recording values to the appropriate vector for run details\n","      topic_vec.append(y)\n","      ratio_vec.append(z)\n","      length_vec.append(n)\n","\n","      #Recording run details as a DataFrame object\n","      outputs.append(DataFrame(data={'Topic':topic_vec[k],'Ratio':ratio_vec[k]}))\n","\n","    #Record Run Lengths and make a DataFrame object\n","    output_len = {'Run':list(range(1,(runs+1),1)),'Length':length_vec}\n","    results2 = DataFrame(data=output_len)\n","\n","    #Record Length results to the appropriate vector\n","    length_dat.append(results2)\n","\n","    #Combine the Run results and Record to the appropriate vector\n","    results1 = pd.concat(outputs,axis=1)\n","    run_dat.append(results1)\n","\n","    #Determine and record the average topic number for the runs\n","    val_to_round = sum(topic_final_vec)/len(topic_final_vec) \n","    average_topics.append(int(val_to_round))\n","\n","    #Print timer and update progress bar\n","    print(time.process_time() - start)\n","    pbar.update(1)    \n","\n","  pbar.close()\n","  return(average_topics,run_dat,length_dat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gUUilfsHwI6z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1599060275332,"user_tz":-180,"elapsed":8943,"user":{"displayName":"Alexandra G","photoUrl":"","userId":"12867522197621895843"}},"outputId":"ff793795-4b2c-41f2-cd53-355a2a57a426"},"source":["#Set vector of question numbers to test\n","n_tot = len(corpus)\n","n_end = n_tot // 100\n","\n","q_uest_list = list(range(100,n_tot+1,100))\n","q_uest_list[n_end-1] = n_tot\n","\n","#Partition the question list to account for runtime\n","q_ues_1 = q_uest_list[:5]\n","q_ues_2 = q_uest_list[5:8]\n","q_ues_3 = q_uest_list[8:11]\n","q_ues_4 = q_uest_list[11:13] \n","\n","#Check\n","#print(q_uest_list)\n","print(q_ues_1,q_ues_2,q_ues_3,q_ues_4)\n","#print(q_ues_1+q_ues_2+q_ues_3+q_ues_4)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[100, 200, 300, 400, 500] [600, 700, 800] [900, 1000, 1100] [1200, 1303]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"63oohiD9xu2c","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":67},"outputId":"2d9a9b4a-77e6-497a-c18d-c19e43a8ad54"},"source":["[avgs_1,runs_1,lengths_1] = get_averages(q_ues_1)\n","\n","#Upload the Path and Length data to Drive (specify location)\n","for i in list(range(0,len(q_ues_1),1)):\n","  runs = runs_1[i]\n","  lengths = lengths_1[i]\n","\n","  filename1 = 'UntaggedA_Paths_' + str(q_ues_1[i]) + '.csv'\n","  filename2 = 'UntaggedA_Lengths_' + str(q_ues_1[i]) + '.csv'\n","\n","  runs.to_csv(filename1)\n","  lengths.to_csv(filename2)\n","\n","  shutil.copy2(filename1, '/content/drive/My Drive/MLResearchProject/Average Termination Untagged')\n","  shutil.copy2(filename2, '/content/drive/My Drive/MLResearchProject/Average Termination Untagged')  \n","\n","#Upload Average(s) data to Drive (specify location) \n","output_1 = {'Questions Used':q_ues_1,'Average Topic Number Found':avgs_1}\n","avgs_output_1 = DataFrame(data=output_1)\n","avgs_output_1.to_csv('UntaggedA_Averages_1.csv')\n","\n","!cp UntaggedA_Averages_1.csv \"/content/drive/My Drive/MLResearchProject/Average Termination Untagged\""],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","\n","  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"KxtGmVEpFSME","colab_type":"code","colab":{}},"source":["[avgs_2,runs_2,lengths_2] = get_averages(q_ues_2)\n","\n","#Upload the Path and Length data to Drive (specify location)\n","for i in list(range(0,len(ques_2),1)):\n","  runs = runs_2[i]\n","  lengths = lengths_2[i]\n","\n","  filename1 = 'UntaggedA_Paths_' + str(q_ues_2[i]) + '.csv'\n","  filename2 = 'UntaggedA_Lengths_' + str(q_ues_2[i]) + '.csv'\n","\n","  runs.to_csv(filename1)\n","  lengths.to_csv(filename2)\n","\n","  shutil.copy2(filename1, '/content/drive/My Drive/MLResearchProject/Average Termination Untagged')\n","  shutil.copy2(filename2, '/content/drive/My Drive/MLResearchProject/Average Termination Untagged')  \n","\n","#Upload Average(s) data to Drive (specify location) \n","output_2 = {'Questions Used':q_ues_2,'Average Topic Number Found':avgs_2}\n","avgs_output_2 = DataFrame(data=output_2)\n","avgs_output_2.to_csv('UntaggedA_Averages_2.csv')\n","\n","!cp UntaggedA_Averages_2.csv \"/content/drive/My Drive/MLResearchProject/Average Termination Untagged\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jAbExUGnV-tW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"status":"ok","timestamp":1598969044533,"user_tz":-60,"elapsed":20177866,"user":{"displayName":"Nick Fernandes","photoUrl":"","userId":"06789908458132586616"}},"outputId":"9aeb96d7-252d-4c7f-cbc8-2772d5544018"},"source":["[avgs_3,runs_3,lengths_3] = get_averages(q_ues_3)\n","\n","#Upload the Path and Length data to Drive (specify location)\n","for i in list(range(0,len(q_ues_3),1)):\n","  runs = runs_3[i]\n","  lengths = lengths_3[i]\n","\n","  filename1 = 'UntaggedA_Paths_' + str(q_ues_3[i]) + '.csv'\n","  filename2 = 'UntaggedA_Lengths_' + str(q_ues_3[i]) + '.csv'\n","\n","  runs.to_csv(filename1)\n","  lengths.to_csv(filename2)\n","\n","  shutil.copy2(filename1, '/content/drive/My Drive/MLResearchProject/Average Termination Untagged')\n","  shutil.copy2(filename2, '/content/drive/My Drive/MLResearchProject/Average Termination Untagged')  \n","\n","#Upload Average(s) data to Drive (specify location) \n","output_3 = {'Questions Used':q_ues_3,'Average Topic Number Found':avgs_3}\n","avgs_output_3 = DataFrame(data=output_3)\n","avgs_output_3.to_csv('UntaggedA_Averages_3.csv')\n","\n","!cp TaggedA_Averages_3.csv \"/content/drive/My Drive/MLResearchProject/Average Termination Untagged\""],"execution_count":null,"outputs":[{"output_type":"stream","text":[" 33%|███▎      | 1/3 [1:30:10<3:00:20, 5410.16s/it]"],"name":"stderr"},{"output_type":"stream","text":["5865.186952907\n"],"name":"stdout"},{"output_type":"stream","text":["\r 67%|██████▋   | 2/3 [3:29:24<1:38:53, 5933.49s/it]"],"name":"stderr"},{"output_type":"stream","text":["7753.0007511329995\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 3/3 [5:36:17<00:00, 6725.85s/it]"],"name":"stderr"},{"output_type":"stream","text":["8379.076947503\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"BnRsnCeuWGwP","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1598933247858,"user_tz":-60,"elapsed":16260739,"user":{"displayName":"Nick Fernandes","photoUrl":"","userId":"06789908458132586616"}},"outputId":"bf2da588-7b8c-4022-aca2-91681f257279"},"source":["[avgs_4,runs_4,lengths_4] = get_averages(q_ues_4)\n","\n","#Upload the Path and Length data to Drive (specify location)\n","for i in list(range(0,len(q_ues_4),1)):\n","  runs = runs_4[i]\n","  lengths = lengths_4[i]\n","\n","  filename1 = 'UntaggedA_Paths_' + str(q_ues_4[i]) + '.csv'\n","  filename2 = 'UntaggedA_Lengths_' + str(q_ues_4[i]) + '.csv'\n","\n","  runs.to_csv(filename1)\n","  lengths.to_csv(filename2)\n","\n","  shutil.copy2(filename1, '/content/drive/My Drive/MLResearchProject/Average Termination Untagged')\n","  shutil.copy2(filename2, '/content/drive/My Drive/MLResearchProject/Average Termination Untagged')  \n","\n","#Upload Average(s) data to Drive (specify location) \n","output_4 = {'Questions Used':q_ues_4,'Average Topic Number Found':avgs_4}\n","avgs_output_4 = DataFrame(data=output_4)\n","avgs_output_4.to_csv('TaggedA_Averages_4.csv')\n","\n","!cp TaggedA_Averages_4.csv \"/content/drive/My Drive/MLResearchProject/Average Termination Untagged\""],"execution_count":null,"outputs":[{"output_type":"stream","text":[" 50%|█████     | 1/2 [2:24:13<2:24:13, 8653.53s/it]"],"name":"stderr"},{"output_type":"stream","text":["9538.829588979\n"],"name":"stdout"},{"output_type":"stream","text":["100%|██████████| 2/2 [4:31:00<00:00, 8130.10s/it]"],"name":"stderr"},{"output_type":"stream","text":["8687.161869608997\n"],"name":"stdout"},{"output_type":"stream","text":["\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"0TIgRr4oy77e","colab_type":"code","colab":{}},"source":["# output = {'Questions Used':q_uest_list,'Average Topic Number Found':avgs_1+avgs_2+avgs_3}\n","# results = DataFrame(data=output)\n","# results.to_csv('TaggedA.csv')\n","\n","# !cp TaggedA.csv \"/content/drive/My Drive/MLResearchProject/Average Termination\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6WQZEvCmBuqi","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}